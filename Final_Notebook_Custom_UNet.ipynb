{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Stefano97/AN2DL_Project2/blob/master/transferLearningAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEZzWExHTVY8"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e1ApRc9qOKL"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Stefano97/AN2DL_Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRufo-U3GlXl"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2_iSRajIpxc"
   },
   "outputs": [],
   "source": [
    "! cp -R \"/content/drive/My Drive/ann-and-dl-image-segmentation.zip\" \"/content/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQf4jxH-C4gD"
   },
   "outputs": [],
   "source": [
    "!unzip ./*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOeQTOrJXrwZ"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6pYRQ-6TVba"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_augumentation = True\n",
    "\n",
    "if data_augumentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=5,\n",
    "                                              zoom_range=0.2,\n",
    "                                              horizontal_flip=True,\n",
    "                                              vertical_flip=True,\n",
    "                                              fill_mode='constant', \n",
    "                                              cval=0,\n",
    "                                              rescale=1./255,\n",
    "                                              validation_split=0.3)\n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=5,\n",
    "                                              zoom_range=0.2,\n",
    "                                              horizontal_flip=True,\n",
    "                                              vertical_flip=True,\n",
    "                                              fill_mode='constant', \n",
    "                                              cval=0,\n",
    "                                              rescale = 1./255, \n",
    "                                              validation_split=0.3)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.3)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale = 1./255,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset in the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB4AxkLfTVe4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd, 'Segmentation_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "#num_classes=21\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
    "# to apply the same transformations/shuffling to images and corresponding masks\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset=\"training\")  \n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode=\"grayscale\",\n",
    "                                                         seed=SEED,\n",
    "                                                         subset=\"training\")\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset=\"validation\")  \n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode=\"grayscale\",\n",
    "                                                         seed=SEED,\n",
    "                                                         subset=\"validation\")\n",
    "\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI42-SDjwcCt"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "training = []\n",
    "for imgName in train_img_gen.filenames:\n",
    "    matchObj = re.search(r'[^\\\\\\\\/]+$',imgName,re.M)    \n",
    "    file_name = matchObj.group()\n",
    "    training.append(file_name)\n",
    "    \n",
    "validation = []\n",
    "for imgName in valid_img_gen.filenames:\n",
    "    matchObj = re.search(r'[^\\\\\\\\/]+$',imgName,re.M)    \n",
    "    file_name = matchObj.group()\n",
    "    validation.append(file_name)\n",
    "\n",
    "# dictionary with the format shown in the Evaluation tab\n",
    "dataset_split = {'training': training , 'validation': validation}   \n",
    "with open('dataset_split.json', 'w') as fp:\n",
    "    json.dump(dataset_split, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images in the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tm-OGnHiTVhx"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2)\n",
    "fig.show()\n",
    "\n",
    "iterator = iter(train_gen)\n",
    "\n",
    "for _ in range(1000):\n",
    "    img, target = next(iterator)\n",
    "    img = img[0]   # First element\n",
    "    img = img * 255  # denormalize\n",
    "    target = target[0]\n",
    "    \n",
    "    target = target.squeeze(-1)\n",
    "    \n",
    "    \n",
    "    # Assign colors (just for visualization)\n",
    "    target_img = np.zeros([256, 256, 3])\n",
    "\n",
    "    target_img[np.where(target == 0.0)] = [0, 0, 0]\n",
    "    target_img[np.where(target == 1.0)] = [255, 255, 255]\n",
    "\n",
    "\n",
    "    ax[0].imshow(np.uint8(img))\n",
    "    ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvpfB37hsH27"
   },
   "outputs": [],
   "source": [
    "def Convolutional_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \n",
    "    # First Layer\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters,\n",
    "                                kernel_size = (kernel_size, kernel_size),\n",
    "                                kernel_initializer = 'he_normal', \n",
    "                                padding = 'same')(input_tensor)\n",
    "    \n",
    "    if batchnorm: x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # Second Layer\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters, \n",
    "                               kernel_size = (kernel_size, kernel_size),\n",
    "                               kernel_initializer = 'he_normal', \n",
    "                               padding = 'same')(input_tensor)\n",
    "    \n",
    "    if batchnorm: x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "def UNet_model(input_img, n_filters = 16, dropout = 0.1, batchnorm = True, down_skip_connection=True):\n",
    "    # Down Sampling\n",
    "    main1 = Convolutional_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    skip_up4 = main1\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        skip1 = tf.keras.layers.Conv2D(filters = n_filters*1, kernel_size = (2,2),kernel_initializer = 'he_normal',strides=(2,2))(input_img) #128x128\n",
    "        \n",
    "    \n",
    "    main1 = tf.keras.layers.MaxPooling2D((2, 2))(main1)\n",
    "    main1 = tf.keras.layers.Dropout(dropout)(main1)\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        main2 = tf.keras.layers.Add()([main1, skip1])\n",
    "    else:\n",
    "        main2 = main1\n",
    "        \n",
    "    main2 = Convolutional_block(main2, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    skip_up3 = main2\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        skip2 = tf.keras.layers.Conv2D(filters = n_filters*2, kernel_size = (2,2),kernel_initializer = 'he_normal',strides=(2,2))(main1) \n",
    "    \n",
    "    main2 = tf.keras.layers.MaxPooling2D((2, 2))(main2)\n",
    "    main2 = tf.keras.layers.Dropout(dropout)(main2)\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        main3 = tf.keras.layers.Add()([main2, skip2])\n",
    "    else:\n",
    "        main3 = main2\n",
    "        \n",
    "    main3 = Convolutional_block(main3, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    skip_up2 = main3\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        skip3 = tf.keras.layers.Conv2D(filters = n_filters*4, kernel_size = (2,2),kernel_initializer = 'he_normal',strides=(2,2))(main2) #exp\n",
    "    \n",
    "    main3 = tf.keras.layers.MaxPooling2D((2, 2))(main3)\n",
    "    main3 = tf.keras.layers.Dropout(dropout)(main3)\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        main4 = tf.keras.layers.Add()([main3, skip3])\n",
    "    else:\n",
    "        main4 = main3\n",
    "    \n",
    "    main4 = Convolutional_block(main4, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    skip_up1 = main4\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        skip4 = tf.keras.layers.Conv2D(filters = n_filters*8, kernel_size = (2,2),kernel_initializer = 'he_normal',strides=(2,2))(main3) #exp\n",
    "    \n",
    "    main4 = tf.keras.layers.MaxPooling2D((2, 2))(main4)\n",
    "    main4 = tf.keras.layers.Dropout(dropout)(main4)\n",
    "    \n",
    "    if down_skip_connection:\n",
    "        main5 = tf.keras.layers.Add()([main4, skip4])\n",
    "    else:\n",
    "        main5 = main4\n",
    "    \n",
    "    main5 = Convolutional_block(main5, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Up Sampling\n",
    "    up1 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(main5)\n",
    "    up1 = tf.keras.layers.concatenate([up1, skip_up1])\n",
    "    up1 = tf.keras.layers.Dropout(dropout)(up1)\n",
    "    up1 = Convolutional_block(up1, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    up2 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(up1)\n",
    "    up2 = tf.keras.layers.concatenate([up2, skip_up2])\n",
    "    up2 = tf.keras.layers.Dropout(dropout)(up2)\n",
    "    up2 = Convolutional_block(up2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    up3 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(up2)\n",
    "    up3 = tf.keras.layers.concatenate([up3, skip_up3])\n",
    "    up3 = tf.keras.layers.Dropout(dropout)(up3)\n",
    "    up3 = Convolutional_block(up3, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    up4 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(up3)\n",
    "    up4 = tf.keras.layers.concatenate([up4, skip_up4])\n",
    "    up4 = tf.keras.layers.Dropout(dropout)(up4)\n",
    "    up4 = Convolutional_block(up4, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(up4)\n",
    "    model = tf.keras.models.Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsMYoAqXslHN"
   },
   "outputs": [],
   "source": [
    "input_img = tf.keras.layers.Input((256, 256, 3), name='img')\n",
    "model = UNet_model(input_img,n_filters=16)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "#We inserts the down_skip_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TrmQRqTIAxtu"
   },
   "source": [
    "## PREPARE THE MODEL FOR TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EgjrYuhTVnF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) \n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "def my_IoU(y_true, y_pred):\n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[my_IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hxOMiq-TVp4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='my_IoU', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_img_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF-k-XFJB_vJ"
   },
   "outputs": [],
   "source": [
    "model.load_weights('./segmentation_experiments/CNN_Dec14_18-36-15/ckpts/cp_10.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8OquR_Fm7Kw"
   },
   "source": [
    "## TEST WITH KAGGLE CREATING FILE CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1JMrTJjSO8X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./output/'):\n",
    "    if not os.path.exists(results_dir):\n",
    "      os.makedirs(results_dir)\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + value + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukRGfjCXLXRb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)\n",
    "\n",
    "image_filenames = next(os.walk('./Segmentation_Dataset/test/images/img/'))[2]                          \n",
    "results = {}\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img = Image.open('./Segmentation_Dataset/test/images/img/'+image_name).convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array*1./255 #normalization\n",
    "    img_array = np.expand_dims(img_array,0) #needed for fixed dim of input in the model\n",
    "    output = model.predict(img_array)\n",
    "    output = tf.cast(output > 0.5, tf.int32) \n",
    "    output = output.numpy()\n",
    "    results[image_name[:-4]] = rle_encode(output)\n",
    "    \n",
    "create_csv(results)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Preprocessing attempt.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
