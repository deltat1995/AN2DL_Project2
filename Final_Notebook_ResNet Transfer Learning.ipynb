{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Stefano97/AN2DL_Project2/blob/master/transferLearningAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEZzWExHTVY8"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e1ApRc9qOKL"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Stefano97/AN2DL_Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRufo-U3GlXl"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2_iSRajIpxc"
   },
   "outputs": [],
   "source": [
    "! cp -R \"/content/drive/My Drive/ann-and-dl-image-segmentation.zip\" \"/content/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQf4jxH-C4gD"
   },
   "outputs": [],
   "source": [
    "!unzip ./*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOeQTOrJXrwZ"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6pYRQ-6TVba"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "data_augumentation = True\n",
    "\n",
    "if data_augumentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=5,\n",
    "                                              zoom_range=0.2,\n",
    "                                              horizontal_flip=True,\n",
    "                                              vertical_flip=True,\n",
    "                                              fill_mode='constant', \n",
    "                                              cval=0,\n",
    "                                              preprocessing_function=preprocess_input,\n",
    "                                              validation_split=0.3)\n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=5,\n",
    "                                              zoom_range=0.2,\n",
    "                                              horizontal_flip=True,\n",
    "                                              vertical_flip=True,\n",
    "                                              fill_mode='constant', \n",
    "                                              cval=0,\n",
    "                                              rescale = 1./255, \n",
    "                                              validation_split=0.3)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.3)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale = 1./255,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset in the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB4AxkLfTVe4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd, 'Segmentation_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "#num_classes=21\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
    "# to apply the same transformations/shuffling to images and corresponding masks\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset=\"training\")  \n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode=\"grayscale\",\n",
    "                                                         seed=SEED,\n",
    "                                                         subset=\"training\")\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset=\"validation\")  \n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode=\"grayscale\",\n",
    "                                                         seed=SEED,\n",
    "                                                         subset=\"validation\")\n",
    "\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI42-SDjwcCt"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "training = []\n",
    "for imgName in train_img_gen.filenames:\n",
    "    matchObj = re.search(r'[^\\\\\\\\/]+$',imgName,re.M)    \n",
    "    file_name = matchObj.group()\n",
    "    training.append(file_name)\n",
    "    \n",
    "validation = []\n",
    "for imgName in valid_img_gen.filenames:\n",
    "    matchObj = re.search(r'[^\\\\\\\\/]+$',imgName,re.M)    \n",
    "    file_name = matchObj.group()\n",
    "    validation.append(file_name)\n",
    "\n",
    "# dictionary with the format shown in the Evaluation tab\n",
    "dataset_split = {'training': training , 'validation': validation}   \n",
    "with open('dataset_split.json', 'w') as fp:\n",
    "    json.dump(dataset_split, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images in the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tm-OGnHiTVhx"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2)\n",
    "fig.show()\n",
    "\n",
    "iterator = iter(train_gen)\n",
    "\n",
    "for _ in range(1000):\n",
    "    img, target = next(iterator)\n",
    "    img = img[0]   # First element\n",
    "    img = img * 255  # denormalize\n",
    "    target = target[0]\n",
    "    \n",
    "    target = target.squeeze(-1)\n",
    "    \n",
    "    \n",
    "    # Assign colors (just for visualization)\n",
    "    target_img = np.zeros([256, 256, 3])\n",
    "\n",
    "    target_img[np.where(target == 0.0)] = [0, 0, 0]\n",
    "    target_img[np.where(target == 1.0)] = [255, 255, 255]\n",
    "\n",
    "\n",
    "    ax[0].imshow(np.uint8(img))\n",
    "    ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ziP09IyInRih"
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2ij4jQAo9aa"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JcblkK_nnQv2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(model, n_filters = 16, dropout = 0.2, batchnorm = True,finetuning=True):\n",
    "    if finetuning:\n",
    "        freeze_until = 208\n",
    "        # layer from which we want to fine-tune\n",
    "        for layer in model.layers[:freeze_until]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        model.trainable = False\n",
    "        \n",
    "    # Contracting Path\n",
    "    inputlayer = model.get_layer('input_1') #WARNING: the input layer name changes every time you execute the download of ResNet application (code above)\n",
    "    layer1 = model.get_layer('conv1_relu')\n",
    "    o1 = layer1.output #128x128\n",
    "    layer2 = model.get_layer('conv2_block3_out')\n",
    "    o2 = layer2.output #64x64\n",
    "    layer3 = model.get_layer('conv3_block4_out')\n",
    "    o3 = layer3.output #32x32\n",
    "    layer4 = model.get_layer('conv4_block6_out')\n",
    "    o4 = layer4.output #16x16\n",
    "    layer5 = model.get_layer('conv5_block3_out')\n",
    "    o5 = layer5.output #8x8\n",
    "    c5 = conv2d_block(o5, n_filters = n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u5 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u5 = tf.keras.layers.concatenate([u5, o4])\n",
    "    u5 = tf.keras.layers.Dropout(dropout)(u5)\n",
    "    cx = conv2d_block(u5, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(cx)\n",
    "    u6 = tf.keras.layers.concatenate([u6, o3])\n",
    "    u6 = tf.keras.layers.Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, o2])\n",
    "    u7 = tf.keras.layers.Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, o1])\n",
    "    u8 = tf.keras.layers.Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = tf.keras.layers.Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = tf.keras.models.Model(inputs=inputlayer.input, outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_unet(model,n_filters=8)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "#We tried the transfer learning with this way but the IoU_learning increases quickly in the first epoch around 60%, but\n",
    "#the IoU_validation remains fixed around 26%. We don't know why!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TrmQRqTIAxtu"
   },
   "source": [
    "## PREPARE THE MODEL FOR TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EgjrYuhTVnF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) \n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "def my_IoU(y_true, y_pred):\n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[my_IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hxOMiq-TVp4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='my_IoU', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_img_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF-k-XFJB_vJ"
   },
   "outputs": [],
   "source": [
    "model.load_weights('./segmentation_experiments/CNN_Dec14_18-36-15/ckpts/cp_10.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8OquR_Fm7Kw"
   },
   "source": [
    "## TEST WITH KAGGLE CREATING FILE CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1JMrTJjSO8X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./output/'):\n",
    "    if not os.path.exists(results_dir):\n",
    "      os.makedirs(results_dir)\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + value + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukRGfjCXLXRb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)\n",
    "\n",
    "image_filenames = next(os.walk('./Segmentation_Dataset/test/images/img/'))[2]                          \n",
    "results = {}\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img = Image.open('./Segmentation_Dataset/test/images/img/'+image_name).convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    #img_array = img_array*1./255 #normalization\n",
    "    img_array = np.expand_dims(img_array,0) #needed for fixed dim of input in the model\n",
    "    img_array = preprocess_input(img_array)\n",
    "    output = model.predict(img_array)\n",
    "    output = tf.cast(output > 0.5, tf.int32) \n",
    "    output = output.numpy()\n",
    "    results[image_name[:-4]] = rle_encode(output)\n",
    "    \n",
    "create_csv(results)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Preprocessing attempt.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
